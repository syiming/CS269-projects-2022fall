---
layout: post
comments: true
title: Proposal
author: Siqi Liu, Yiming Shi (Team 11)
date: 2022-10-12
---


> Imitation learning is wildly used in Reinforcement learning field, and allow the agent to mimic the action of a human. Imitation learning is also used in autonomous driving. However, simple imitation learning via behavior cloning is not sufficient as driving senarials are sometimes very complex. In this project, we will explore the combination with imitation learning and other reinforcement learning methods to handle complex senarials. 
<!-- (prev proposal)> Ususally driving involves multiple intelligent agents, intelligent machine or human. With more information cooperated, agents may performs differently to achieve their goals. In this projects, we want to research about Reinforcement Learning (RL) based method such that all the agents collaborate with each other to achieve the best goal in total. -->
<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction 
Recently, Reinforcement learning has been wildly used in autonomous driving. Since the driving task has high complexity and hard to construct a safe model or policy, imitation learning by behavior cloning becomes popular as it allows the agent to be trained to learn from a human expert and thus quickly learn to plan the action based on the complex environment and take actions. However, imitation learning is also suffered from issues such as failing unseen complex scenarios. In this project, we are aiming on reproducing a safe driving model based on imitation learning, analyzing failing cases for imitation learning and exploring ways such as adding loss besides imitation loss to discourage certain undesired behavior.

<!-- As 5G techniques becomes more mature, vehicle-to-everything (V2X) becomes possible. This allows vehicles to communicate with any entity that may affect, or may be affected by, the vehicle. A vehicle may use these information to act differently to achieve the final goal.  -->

## Related Work
### Platform
The platform we are going to work on is CARLA. It is an open source driving simulator that able to construct simple and complex senarios.


## Proposed Work
Our project should be mainly two parts. In the first part, we will reproduce the result using imitation learning. In the second phase, we will try to add policy or policy based learning to encourage the desired behavior and punish the undesired behavior. We will test these under restrictions such as stop sign, speed limitation and so on.

## Expected Result
We will first try to reproduce the result with imitation learning, we are expecting the agent are able to dring under simple environment without crashing. We alse expect that the result with imitation learning plus other reinforcement learning, we will reach much better result on complex senarios.

## References
1. Mayank Bansal, Alex Krizhevsky, & Abhĳit S. Ogale (2018). ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst. CoRR, abs/1812.03079.
2. Haan, P.D., Jayaraman, D., & Levine, S. (2019). Causal Confusion in Imitation Learning. NeurIPS.
3. Alexey Dosovitskiy, Germán Ros, Felipe Codevilla, Antonio M. Lόpez, & Vladlen Koltun (2017). CARLA: An Open Urban Driving Simulator. CoRR, abs/1711.03938.
4. Jinyun Zhou, Rui Wang, Xu Liu, Yifei Jiang, Shu Jiang, Jiaming Tao, Jinghao Miao, & Shiyu Song (2021). Exploring Imitation Learning for Autonomous Driving with Feedback Synthesizer and Differentiable Rasterization. CoRR, abs/2103.01882.